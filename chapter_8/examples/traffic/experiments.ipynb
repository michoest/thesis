{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Training an RL restrictor for a discrete action space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(f'{os.getcwd()}/../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from drama.wrapper import RestrictionWrapper\n",
    "from drama.utils import flatdim\n",
    "\n",
    "from examples.traffic_new.env import TrafficEnvironment\n",
    "from examples.traffic_new.agent import TrafficAgent\n",
    "from examples.traffic_new.restrictor import TrafficRestrictor\n",
    "from examples.traffic_new.utils import create_graph, powerset\n",
    "from examples.utils import play, ReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothen(data, kernel_size):\n",
    "    kernel = np.ones(kernel_size) / kernel_size\n",
    "\n",
    "    if data.ndim == 1:\n",
    "        return np.convolve(data, kernel, mode='same')\n",
    "    elif data.ndim == 2:\n",
    "        return np.array([np.convolve(col, kernel, mode='same') for col in data.T]).T\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_graph([\n",
    "    ((0, 1), (0, 8, 1)), \n",
    "    ((0, 2), (11, 0, 0)), \n",
    "    ((1, 2), (1, 0, 0)), \n",
    "    ((1, 3), (11, 0, 0)), \n",
    "    ((2, 3), (0, 8, 1))\n",
    "])\n",
    "\n",
    "possible_start_and_target_nodes = [(0, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes = graph.number_of_nodes()\n",
    "number_of_edges = graph.number_of_edges()\n",
    "\n",
    "edges = {edge: i for i, edge in enumerate(graph.edges)}\n",
    "routes = sum((list(nx.all_simple_paths(graph, s, t)) for s, t in possible_start_and_target_nodes), [])\n",
    "\n",
    "# Create all valid edge restrictions as sets of allowed edges\n",
    "all_start_and_target_nodes = set(sum(possible_start_and_target_nodes, tuple()))\n",
    "valid_edge_restrictions = []\n",
    "for allowed_edges in powerset(graph.edges):\n",
    "    subgraph = graph.edge_subgraph(allowed_edges)\n",
    "    if all_start_and_target_nodes.issubset(subgraph.nodes) and all(nx.has_path(subgraph, s, t) for s, t in possible_start_and_target_nodes):\n",
    "        valid_edge_restrictions.append([edge in allowed_edges for edge in edges.keys()])\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_agents = 2\n",
    "\n",
    "agents = {f'agent_{i}': TrafficAgent(routes, edges, seed=seed) for i in range(number_of_agents)}\n",
    "env = TrafficEnvironment(graph, list(agents.keys()), possible_start_and_target_nodes, routes, number_of_steps=100, seed=seed)\n",
    "\n",
    "restrictor = TrafficRestrictor(edges, routes, valid_edge_restrictions, total_timesteps=1000, seed=seed)\n",
    "env = RestrictionWrapper(env, restrictor, restrictor_reward_fns={'restrictor_0': lambda env, rewards: rewards[env.agent_selection]}, return_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 500_000\n",
    "\n",
    "restricted_history = pd.DataFrame(columns=['episode', 'episode_step', 'agent', 'observation', 'reward', 'action'], index=(range(total_timesteps)))\n",
    "replay_buffer = ReplayBuffer(state_dim=flatdim(restrictor.observation_space), action_dim=flatdim(restrictor.action_space))\n",
    "\n",
    "# Do not render during training\n",
    "env.unwrapped.render_mode = None\n",
    "\n",
    "current_timestep = 0\n",
    "current_episode = 0\n",
    "t = tqdm(total=total_timesteps)\n",
    "\n",
    "while current_timestep < total_timesteps:\n",
    "    env.reset()\n",
    "    current_episode += 1\n",
    "    current_episode_timestep = 0\n",
    "    previous_restrictor_observation = None\n",
    "\n",
    "    for agent in env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "        if agent == 'restrictor_0':\n",
    "            if previous_restrictor_observation is not None:\n",
    "                restrictor.learn(previous_restrictor_observation, previous_restrictor_action, observation, reward, termination or truncation)\n",
    "\n",
    "            action = restrictor.act(observation)\n",
    "\n",
    "            previous_restrictor_observation = observation\n",
    "            previous_restrictor_action = action\n",
    "        else:\n",
    "            action = agents[agent].act(observation)\n",
    "\n",
    "        if termination or truncation:\n",
    "            action = None\n",
    "        else:\n",
    "            restricted_history.loc[current_timestep] = pd.Series({'episode': current_episode, \n",
    "                                               'episode_step': current_episode_timestep, \n",
    "                                               'agent': agent,\n",
    "                                               'observation': observation, \n",
    "                                               'reward': reward, \n",
    "                                               'action': action}\n",
    "                                               )\n",
    "            \n",
    "            current_timestep += 1\n",
    "            current_episode_timestep += 1\n",
    "\n",
    "        env.step(action)\n",
    "\n",
    "        t.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5_000\n",
    "\n",
    "valid_edge_restriction_sets = ['{' + ', '.join(f'{i}' for i, allowed in enumerate(restriction) if allowed) + '}' for restriction in valid_edge_restrictions]\n",
    "\n",
    "restrictor_actions = restricted_history[restricted_history.agent == 'restrictor_0']['action'].astype(int)\n",
    "one_hot_restrictor_actions = np.eye(len(valid_edge_restrictions))[restrictor_actions.to_numpy().reshape(-1)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "data = pd.DataFrame(smoothen(one_hot_restrictor_actions, kernel_size=kernel_size), index=restrictor_actions.index, columns=valid_edge_restriction_sets)\n",
    "lines = ax.plot(data.iloc[kernel_size:-kernel_size], color='gray', lw=1)\n",
    "\n",
    "lines[11].set_color('red')\n",
    "ax.legend(labels=valid_edge_restriction_sets, loc='center left', bbox_to_anchor=(0.95, 0.5))\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "ax.set_ylabel('Frequency of restriction')\n",
    "ax.set_xlabel('Time step')\n",
    "\n",
    "fig.savefig('traffic-result-actions.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
