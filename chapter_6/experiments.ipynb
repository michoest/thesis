{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Finding optimal restrictions via Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium.spaces import Box, MultiDiscrete, Dict\n",
    "from ray import tune\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.agent import ParametricAgentModel\n",
    "from src.governance import PassiveGovernancePolicy\n",
    "from src.logger import CustomMetricsLogger\n",
    "from src.env import FMAS_Environment, GMAS_Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_without_governance(config):\n",
    "    NUMBER_OF_AGENTS = config['NUMBER_OF_AGENTS']\n",
    "    NUMBER_OF_ACTIONS = config['NUMBER_OF_ACTIONS']\n",
    "    NUMBER_OF_STEPS_PER_EPISODE = config['NUMBER_OF_STEPS_PER_EPISODE']\n",
    "    ALPHA = config['ALPHA']\n",
    "    ENV = config['ENV']\n",
    "    NUMBER_OF_TIMESTEPS = config['NUMBER_OF_TIMESTEPS']\n",
    "    NUMBER_OF_SAMPLES = config['NUMBER_OF_SAMPLES']\n",
    "    NAME = config['NAME']\n",
    "    LOG_DIR = config['LOG_DIR']\n",
    "\n",
    "    gov_obs_space = Dict({ 'state': MultiDiscrete([NUMBER_OF_ACTIONS] * NUMBER_OF_AGENTS),\n",
    "                           'obs': Box(0, NUMBER_OF_ACTIONS - 1, shape=(3,))})\n",
    "    gov_action_space = MultiDiscrete([2] * NUMBER_OF_ACTIONS)\n",
    "\n",
    "    def policy_mapping_fn(agent_id, episode, **kwargs):\n",
    "        # TODO: Why is agent0 sometimes called?\n",
    "        if 'agent' in agent_id:\n",
    "            print(f'Invalid agent_id ({agent_id})!')\n",
    "\n",
    "        return agent_id if 'agent' not in agent_id else agent_id[5:]\n",
    "\n",
    "    run_config = {\n",
    "        'env': ENV,\n",
    "        'env_config': {\n",
    "          'NUMBER_OF_STEPS_PER_EPISODE': NUMBER_OF_STEPS_PER_EPISODE,\n",
    "          'NUMBER_OF_AGENTS': NUMBER_OF_AGENTS,\n",
    "          'NUMBER_OF_ACTIONS': NUMBER_OF_ACTIONS,\n",
    "          'ALPHA': ALPHA\n",
    "        },\n",
    "        'multiagent': {\n",
    "            'policies': {\n",
    "                **{str(i): (None, None, None, { }) for i in range(NUMBER_OF_AGENTS)},\n",
    "                'gov': (PassiveGovernancePolicy, gov_obs_space, gov_action_space, { })\n",
    "            },\n",
    "            'policy_mapping_fn': policy_mapping_fn,\n",
    "            'policies_to_train': [str(i) for i in range(NUMBER_OF_AGENTS)]\n",
    "        },\n",
    "        'callbacks': CustomMetricsLogger\n",
    "    }\n",
    "\n",
    "    return tune.run('PPO', verbose=1, config=run_config, stop={'timesteps_total': NUMBER_OF_TIMESTEPS},\n",
    "             num_samples=NUMBER_OF_SAMPLES, checkpoint_at_end=True,\n",
    "             name=NAME, local_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_with_governance(config):\n",
    "    NUMBER_OF_AGENTS = config['NUMBER_OF_AGENTS']\n",
    "    NUMBER_OF_ACTIONS = config['NUMBER_OF_ACTIONS']\n",
    "    NUMBER_OF_STEPS_PER_EPISODE = config['NUMBER_OF_STEPS_PER_EPISODE']\n",
    "    ALPHA = config['ALPHA']\n",
    "    ENV = config['ENV']\n",
    "    NUMBER_OF_TIMESTEPS = config['NUMBER_OF_TIMESTEPS']\n",
    "    NUMBER_OF_SAMPLES = config['NUMBER_OF_SAMPLES']\n",
    "    NAME = config['NAME']\n",
    "    LOG_DIR = config['LOG_DIR']\n",
    "\n",
    "    gov_obs_space = Dict({ 'state': MultiDiscrete([NUMBER_OF_ACTIONS] * NUMBER_OF_AGENTS),\n",
    "                           'obs': Box(0, NUMBER_OF_ACTIONS - 1, shape=(3,))})\n",
    "    gov_action_space = MultiDiscrete([2] * NUMBER_OF_ACTIONS)\n",
    "\n",
    "    def policy_mapping_fn(agent_id, episode, **kwargs):\n",
    "        # TODO: Why is agent0 sometimes called?\n",
    "        if 'agent' in agent_id:\n",
    "            print(f'Invalid agent_id ({agent_id})!')\n",
    "\n",
    "        return agent_id if 'agent' not in agent_id else agent_id[5:]\n",
    "\n",
    "    run_config = {\n",
    "        'env': ENV,\n",
    "        'env_config': {\n",
    "          'NUMBER_OF_STEPS_PER_EPISODE': NUMBER_OF_STEPS_PER_EPISODE,\n",
    "          'NUMBER_OF_AGENTS': NUMBER_OF_AGENTS,\n",
    "          'NUMBER_OF_ACTIONS': NUMBER_OF_ACTIONS,\n",
    "          'ALPHA': ALPHA\n",
    "        },\n",
    "        'multiagent': {\n",
    "            'policies': {\n",
    "                **{str(i): (None, None, None, { 'model': {'custom_model': ParametricAgentModel }, 'framework': 'tf' }) for i in range(NUMBER_OF_AGENTS)},\n",
    "                'gov': (None, gov_obs_space, gov_action_space, { })\n",
    "            },\n",
    "            'policy_mapping_fn': policy_mapping_fn,\n",
    "            'policies_to_train': [str(i) for i in range(NUMBER_OF_AGENTS)] + ['gov']\n",
    "        },\n",
    "        'callbacks': CustomMetricsLogger\n",
    "    }\n",
    "\n",
    "    return tune.run('PPO', verbose=1, config=run_config, stop={'timesteps_total': NUMBER_OF_TIMESTEPS},\n",
    "             num_samples=NUMBER_OF_SAMPLES, checkpoint_at_end=True,\n",
    "             name=NAME, local_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_charts(ids):\n",
    "    outer_path = f'{log_dir}/chapter_6'\n",
    "\n",
    "    configurations = list(set(configuration for configuration, scenario in ids.keys()))\n",
    "    scenarios = list(set(scenario for configuration, scenario in ids.keys()))\n",
    "    kpis = ['governance_reward', 'degree_of_restriction']\n",
    "\n",
    "    metrics = {\n",
    "        'governance_reward': 'ray/tune/custom_metrics/episode_state_reward/gov_mean',\n",
    "        'degree_of_restriction': 'ray/tune/custom_metrics/episode_degree_of_restriction/gov_mean'\n",
    "    }\n",
    "\n",
    "    experiment_folders = { key: glob.glob(f'{outer_path}/*{id}*/') for key, id in ids.items() }\n",
    "    event_accumulators = { key: [EventAccumulator(f) for f in folders] for key, folders in experiment_folders.items() }\n",
    "\n",
    "    current, total = 1, sum(len(ea) for ea in event_accumulators.values())\n",
    "    for key, experiment in event_accumulators.items():\n",
    "        for ea in experiment:\n",
    "            print(f'\\rLoading EventAccumulator {current}/{total}...', end='')\n",
    "            ea.Reload()\n",
    "            current += 1\n",
    "\n",
    "    raw_data = { (configuration, scenario, kpi): [list(zip(*ea.Scalars(metrics[kpi]))) for ea in experiment] for kpi in kpis for (configuration, scenario), experiment in event_accumulators.items() }\n",
    "    processed_data = { key: { 'x': np.array(experiment[0][1]), 'y': [np.array(sample[2]) for sample in experiment] } for key, experiment in raw_data.items() }\n",
    "    final_data = { key: { 'x': experiment['x'], 'y': experiment['y'], 'mean': np.mean(experiment['y'], axis=0) } for key, experiment in processed_data.items() }\n",
    "\n",
    "    print(f'Finished!')\n",
    "\n",
    "    save_path = f'{log_dir}/chapter_6/charts'\n",
    "    plt.style.use({'figure.facecolor':'white'})\n",
    "\n",
    "    scenario_names = {\n",
    "        'umas': 'UMAS',\n",
    "        'fmas': 'FMAS',\n",
    "        'gmas': 'GMAS'\n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "        'umas': 'blue',\n",
    "        'fmas': 'red',\n",
    "        'gmas': 'green'\n",
    "    }\n",
    "\n",
    "    for i, configuration in enumerate(configurations):\n",
    "        for j, kpi in enumerate(kpis):\n",
    "            for scenario in scenarios:\n",
    "                x, ys, mean = itemgetter('x', 'y', 'mean')(final_data[(configuration, scenario, kpi)])\n",
    "                color = colors[scenario]\n",
    "                for y in ys:\n",
    "                    plt.plot(x, y, color=color, alpha=0.4, linewidth=0.5)\n",
    "\n",
    "                plt.plot(x, mean, color=color, label=scenario_names[scenario])\n",
    "\n",
    "            plt.ticklabel_format(axis='x', useMathText=True)\n",
    "            plt.xlabel('$t$')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f'{save_path}/{configuration}_{kpi}.png', format='png', bbox_inches='tight')\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'NUMBER_OF_AGENTS': 10,\n",
    "        'NUMBER_OF_ACTIONS': 5,\n",
    "        'NUMBER_OF_STEPS_PER_EPISODE': 100,\n",
    "        'ALPHA': 0.0,\n",
    "        'NUMBER_OF_TIMESTEPS': 12_000,\n",
    "        'NUMBER_OF_SAMPLES': 3,\n",
    "        'NAME': 'dining_diplomats',\n",
    "        'LOG_DIR': './data/'\n",
    "    }\n",
    "\n",
    "# UMAS\n",
    "config['ENV'] = GMAS_Environment\n",
    "run_experiment_without_governance(config)\n",
    "\n",
    "# FMAS\n",
    "config['ENV'] = FMAS_Environment\n",
    "run_experiment_with_governance(config)\n",
    "\n",
    "# GMAS\n",
    "config['ENV'] = GMAS_Environment\n",
    "run_experiment_with_governance(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {\n",
    "        ('tiny', 'umas'): '<id>',\n",
    "        ('tiny', 'fmas'): '<id>',\n",
    "        ('tiny', 'gmas'): '<id>',\n",
    "        ('small', 'umas'): '<id>',\n",
    "        ('small', 'fmas'): '<id>',\n",
    "        ('small', 'gmas'): '<id>',\n",
    "        ('medium', 'umas'): '<id>',\n",
    "        ('medium', 'fmas'): '<id>',\n",
    "        ('medium', 'gmas'): '<id>',\n",
    "        ('large', 'umas'): '<id>',\n",
    "        ('large', 'fmas'): '<id>',\n",
    "        ('large', 'gmas'): '<id>'\n",
    "    }\n",
    "\n",
    "create_charts(ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
